"""
src.app ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã®ãƒ†ã‚¹ãƒˆ
Streamlitã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã®åŸºæœ¬æ©Ÿèƒ½ã‚’ãƒ†ã‚¹ãƒˆ
"""
import pytest
from unittest.mock import patch, MagicMock
import sys
import os

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã‚’ãƒ‘ã‚¹ã«è¿½åŠ 
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

class TestAppImports:
    """ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆãƒ†ã‚¹ãƒˆ"""
    
    def test_import_models(self):
        """modelsãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆãƒ†ã‚¹ãƒˆ"""
        from src.models import ModelConfig, create_model, get_available_models
        assert ModelConfig is not None
        assert create_model is not None
        assert get_available_models is not None
    
    def test_import_streamlit_dependencies(self):
        """Streamlité–¢é€£ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆãƒ†ã‚¹ãƒˆ"""
        import streamlit as st
        from dotenv import load_dotenv
        from langchain_core.messages import HumanMessage, AIMessage
        
        assert st is not None
        assert load_dotenv is not None
        assert HumanMessage is not None
        assert AIMessage is not None


class TestAppConfiguration:
    """ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³è¨­å®šã®ãƒ†ã‚¹ãƒˆ"""
    
    @patch('streamlit.set_page_config')
    def test_page_config(self, mock_config):
        """ãƒšãƒ¼ã‚¸è¨­å®šã®ãƒ†ã‚¹ãƒˆ"""
        # ãƒšãƒ¼ã‚¸è¨­å®šã®å€¤ã‚’ç›´æ¥ãƒ†ã‚¹ãƒˆ
        expected_config = {
            "page_title": "AIãƒãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆ",
            "page_icon": "ğŸ¤–",
            "layout": "centered"
        }
        
        # å®Ÿéš›ã®Streamlitè¨­å®šã‚’ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ãƒˆ
        import streamlit as st
        st.set_page_config(**expected_config)
        
        # è¨­å®šãŒæ­£ã—ãå‘¼ã°ã‚Œã‚‹ã“ã¨ã‚’ç¢ºèª
        mock_config.assert_called_with(**expected_config)


class TestSessionStateInitialization:
    """ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã®åˆæœŸåŒ–ãƒ†ã‚¹ãƒˆ"""
    
    @patch('src.models.get_available_models')
    def test_session_state_messages_init(self, mock_get_models):
        """ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã®åˆæœŸåŒ–ãƒ†ã‚¹ãƒˆ"""
        mock_get_models.return_value = {"GPT-4o": {"provider": "openai"}}
        
        # ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã®ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ãƒˆ
        session_state = {}
        
        # ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã®åˆæœŸåŒ–ãƒ­ã‚¸ãƒƒã‚¯ã‚’ãƒ†ã‚¹ãƒˆ
        if "messages" not in session_state:
            session_state["messages"] = []
        
        assert "messages" in session_state
        assert session_state["messages"] == []
    
    @patch('src.models.get_available_models')
    def test_session_state_model_selection_init(self, mock_get_models):
        """ãƒ¢ãƒ‡ãƒ«é¸æŠã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã®åˆæœŸåŒ–ãƒ†ã‚¹ãƒˆ"""
        mock_models = {
            "GPT-4o": {"provider": "openai"},
            "Claude Sonnet 4": {"provider": "anthropic"}
        }
        mock_get_models.return_value = mock_models
        
        # ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã®ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ãƒˆ
        session_state = {}
        
        # ãƒ¢ãƒ‡ãƒ«é¸æŠã®åˆæœŸåŒ–ãƒ­ã‚¸ãƒƒã‚¯ã‚’ãƒ†ã‚¹ãƒˆ
        if "selected_model" not in session_state:
            available_models = mock_get_models()
            if available_models:
                session_state["selected_model"] = list(available_models.keys())[0]
            else:
                session_state["selected_model"] = None
        
        assert "selected_model" in session_state
        assert session_state["selected_model"] == "GPT-4o"


class TestMessageProcessing:
    """ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸å‡¦ç†ã®ãƒ†ã‚¹ãƒˆ"""
    
    def test_langchain_message_conversion(self):
        """LangChainãƒ¡ãƒƒã‚»ãƒ¼ã‚¸å½¢å¼ã¸ã®å¤‰æ›ãƒ†ã‚¹ãƒˆ"""
        from langchain_core.messages import HumanMessage, AIMessage
        
        # ãƒ†ã‚¹ãƒˆç”¨ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸å±¥æ­´
        messages = [
            {"role": "user", "content": "Hello"},
            {"role": "assistant", "content": "Hi there!"},
            {"role": "user", "content": "How are you?"}
        ]
        
        # å¤‰æ›ãƒ­ã‚¸ãƒƒã‚¯
        langchain_messages = []
        for msg in messages:
            if msg["role"] == "user":
                langchain_messages.append(HumanMessage(content=msg["content"]))
            elif msg["role"] == "assistant":
                langchain_messages.append(AIMessage(content=msg["content"]))
        
        # çµæœã®æ¤œè¨¼
        assert len(langchain_messages) == 3
        assert isinstance(langchain_messages[0], HumanMessage)
        assert langchain_messages[0].content == "Hello"
        assert isinstance(langchain_messages[1], AIMessage)
        assert langchain_messages[1].content == "Hi there!"
        assert isinstance(langchain_messages[2], HumanMessage)
        assert langchain_messages[2].content == "How are you?"


class TestModelIntegration:
    """ãƒ¢ãƒ‡ãƒ«çµ±åˆã®ãƒ†ã‚¹ãƒˆ"""
    
    @patch('src.models.create_model')
    @patch('src.models.get_available_models')
    def test_model_selection_validation(self, mock_get_models, mock_create_model):
        """ãƒ¢ãƒ‡ãƒ«é¸æŠã®æ¤œè¨¼ãƒ†ã‚¹ãƒˆ"""
        # åˆ©ç”¨å¯èƒ½ãªãƒ¢ãƒ‡ãƒ«ã‚’è¨­å®š
        mock_models = {
            "GPT-4o": {"provider": "openai", "description": "OpenAIã®æœ€æ–°ãƒ¢ãƒ‡ãƒ«"},
            "Claude Sonnet 4": {"provider": "anthropic", "description": "Anthropicã®ãƒ¢ãƒ‡ãƒ«"}
        }
        mock_get_models.return_value = mock_models
        
        # ãƒ¢ãƒ‡ãƒ«ä½œæˆã®ãƒ¢ãƒƒã‚¯
        mock_model = MagicMock()
        mock_create_model.return_value = mock_model
        
        # é¸æŠã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«ã®æ¤œè¨¼
        selected_model = "GPT-4o"
        assert selected_model in mock_models
        
        # ãƒ¢ãƒ‡ãƒ«ä½œæˆãƒ†ã‚¹ãƒˆ
        model = mock_create_model(selected_model)
        assert model is not None
        mock_create_model.assert_called_once_with(selected_model)
    
    @patch('src.models.create_model')
    def test_model_creation_failure_handling(self, mock_create_model):
        """ãƒ¢ãƒ‡ãƒ«ä½œæˆå¤±æ•—æ™‚ã®å‡¦ç†ãƒ†ã‚¹ãƒˆ"""
        # ãƒ¢ãƒ‡ãƒ«ä½œæˆãŒå¤±æ•—ã™ã‚‹å ´åˆã‚’ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ãƒˆ
        mock_create_model.return_value = None
        
        selected_model = "InvalidModel"
        model = mock_create_model(selected_model)
        
        # NoneãŒè¿”ã•ã‚Œã‚‹ã“ã¨ã‚’ç¢ºèª
        assert model is None


class TestErrorHandling:
    """ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ã®ãƒ†ã‚¹ãƒˆ"""
    
    def test_missing_api_key_scenario(self):
        """APIã‚­ãƒ¼æœªè¨­å®šæ™‚ã®ã‚·ãƒŠãƒªã‚ªãƒ†ã‚¹ãƒˆ"""
        with patch.dict(os.environ, {}, clear=True):
            from src.models import get_available_models
            
            available_models = get_available_models()
            # APIã‚­ãƒ¼ãŒè¨­å®šã•ã‚Œã¦ã„ãªã„å ´åˆã€åˆ©ç”¨å¯èƒ½ãªãƒ¢ãƒ‡ãƒ«ã¯0å€‹
            assert len(available_models) == 0
    
    @patch('src.models.create_model')
    def test_model_invoke_error_handling(self, mock_create_model):
        """ãƒ¢ãƒ‡ãƒ«å‘¼ã³å‡ºã—ã‚¨ãƒ©ãƒ¼ã®ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ãƒ†ã‚¹ãƒˆ"""
        # ãƒ¢ãƒ‡ãƒ«ãŒä¾‹å¤–ã‚’æŠ•ã’ã‚‹å ´åˆã‚’ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ãƒˆ
        mock_model = MagicMock()
        mock_model.invoke.side_effect = Exception("API Error")
        mock_create_model.return_value = mock_model
        
        model = mock_create_model("GPT-4o")
        
        # ä¾‹å¤–å‡¦ç†ã®ãƒ†ã‚¹ãƒˆ
        try:
            model.invoke([])
            assert False, "ä¾‹å¤–ãŒç™ºç”Ÿã™ã¹ãã§ã™"
        except Exception as e:
            assert str(e) == "API Error"

class TestErrorHandling:
    """ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ã®ãƒ†ã‚¹ãƒˆ"""
    
    def test_error_message_classification(self):
        """ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®åˆ†é¡ãƒ†ã‚¹ãƒˆ"""
        # å®Ÿéš›ã®ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ãƒ­ã‚¸ãƒƒã‚¯ã‚’ãƒ†ã‚¹ãƒˆ
        
        # 401ã‚¨ãƒ©ãƒ¼
        error_401 = "401 Unauthorized"
        assert "401" in error_401
        
        # 429ã‚¨ãƒ©ãƒ¼  
        error_429 = "Error code: 429 - rate_limit_exceeded"
        assert "429" in error_429
        
        # 529ã‚¨ãƒ©ãƒ¼
        error_529 = "Error code: 529 - Overloaded"
        assert "529" in error_529
        assert "overloaded" in error_529.lower()
        
        # ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚¨ãƒ©ãƒ¼
        error_network = "network connection failed"
        assert "network" in error_network.lower()
        
    def test_specific_error_patterns(self):
        """ç‰¹å®šã®ã‚¨ãƒ©ãƒ¼ãƒ‘ã‚¿ãƒ¼ãƒ³ã®ãƒ†ã‚¹ãƒˆ"""
        # æ§˜ã€…ãªã‚¨ãƒ©ãƒ¼ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’ãƒ†ã‚¹ãƒˆ
        test_cases = [
            ("401 Unauthorized", "APIã‚­ãƒ¼"),
            ("403 Forbidden", "æ¨©é™"),
            ("429 rate_limit", "ãƒ¬ãƒ¼ãƒˆåˆ¶é™"),
            ("529 Overloaded", "éè² è·"),
            ("500 Internal Server Error", "ã‚µãƒ¼ãƒãƒ¼"),
            ("network timeout", "ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯"),
        ]
        
        for error_msg, expected_keyword in test_cases:
            # ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ãŒé©åˆ‡ã«åˆ†é¡ã•ã‚Œã‚‹ã“ã¨ã‚’ç¢ºèª
            if "401" in error_msg:
                assert "APIã‚­ãƒ¼" in expected_keyword
            elif "529" in error_msg:
                assert "éè² è·" in expected_keyword


class TestUtilityFunctions:
    """ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£é–¢æ•°ã®ãƒ†ã‚¹ãƒˆ"""
    
    def test_environment_variable_handling(self):
        """ç’°å¢ƒå¤‰æ•°ã®å‡¦ç†ãƒ†ã‚¹ãƒˆ"""
        from dotenv import load_dotenv
        
        # load_dotenvé–¢æ•°ãŒæ­£å¸¸ã«å‹•ä½œã™ã‚‹ã“ã¨ã‚’ç¢ºèª
        result = load_dotenv()
        # ãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã—ãªã„å ´åˆã¯FalseãŒè¿”ã•ã‚Œã‚‹
        assert isinstance(result, bool)
    
    @patch('src.models.get_available_models')
    def test_model_description_display(self, mock_get_models):
        """ãƒ¢ãƒ‡ãƒ«èª¬æ˜è¡¨ç¤ºã®ãƒ†ã‚¹ãƒˆ"""
        mock_models = {
            "GPT-4o": {
                "provider": "openai",
                "description": "OpenAIã®æœ€æ–°ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«ãƒ¢ãƒ‡ãƒ«"
            }
        }
        mock_get_models.return_value = mock_models
        
        available_models = mock_get_models()
        model_name = "GPT-4o"
        
        if model_name in available_models:
            description = available_models[model_name]['description']
            assert description == "OpenAIã®æœ€æ–°ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«ãƒ¢ãƒ‡ãƒ«"